{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting data into Filess Cloud based Postgres Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  ('PostgreSQL 14.4 on aarch64-unknown-linux-musl, compiled by gcc (Alpine 11.2.1_git20220219) 11.2.1 20220219, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd \n",
    "\n",
    "hostname = \"bpd9p.h.filess.io\"\n",
    "database = \"database_wheneverof\"\n",
    "port = \"5432\"\n",
    "username = \"database_wheneverof\"\n",
    "password = \"b2bf3de4d74d8d014fc7370f7b911feeba371894\"\n",
    "\n",
    "# Establishing the connection\n",
    "conn = psycopg2.connect(\n",
    "   database=database, user=username, password=password, host=hostname, port=port\n",
    ")\n",
    "# Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Executing an MYSQL function using the execute() method\n",
    "cursor.execute(\"select version()\")\n",
    "\n",
    "# Fetch a single row using fetchone() method.\n",
    "data = cursor.fetchone()\n",
    "print(\"Connection established to: \", data)\n",
    "\n",
    "# Closing the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data into postgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to PostgreSQL!\n",
      "🏗️ Created/confirmed schema `myschema`.\n",
      "🧹 Dropped table `myschema.machine_data` if it existed.\n",
      "📦 Created table `myschema.machine_data`.\n",
      "⬆️ Inserting 10000 records...\n",
      "✅ Inserted rows 1 to 500\n",
      "✅ Inserted rows 501 to 1000\n",
      "✅ Inserted rows 1001 to 1500\n",
      "✅ Inserted rows 1501 to 2000\n",
      "✅ Inserted rows 2001 to 2500\n",
      "✅ Inserted rows 2501 to 3000\n",
      "✅ Inserted rows 3001 to 3500\n",
      "✅ Inserted rows 3501 to 4000\n",
      "✅ Inserted rows 4001 to 4500\n",
      "✅ Inserted rows 4501 to 5000\n",
      "✅ Inserted rows 5001 to 5500\n",
      "✅ Inserted rows 5501 to 6000\n",
      "✅ Inserted rows 6001 to 6500\n",
      "✅ Inserted rows 6501 to 7000\n",
      "✅ Inserted rows 7001 to 7500\n",
      "✅ Inserted rows 7501 to 8000\n",
      "✅ Inserted rows 8001 to 8500\n",
      "✅ Inserted rows 8501 to 9000\n",
      "✅ Inserted rows 9001 to 9500\n",
      "✅ Inserted rows 9501 to 10000\n",
      "🎉 All data inserted successfully into `{full_table_name}`!\n",
      "🔒 PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# PostgreSQL connection details\n",
    "hostname = \"bpd9p.h.filess.io\"\n",
    "database = \"database_wheneverof\"\n",
    "port = 5432\n",
    "username = \"database_wheneverof\"\n",
    "password = \"b2bf3de4d74d8d014fc7370f7b911feeba371894\"\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = \"data/data.csv\"  # <- Replace with your actual file path\n",
    "table_name = \"machine_data\"\n",
    "schema_name = \"myschema\"  # <- You can rename this schema if you want\n",
    "\n",
    "# Load the CSV into pandas\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Clean column names to be SQL-safe\n",
    "df.columns = [col.strip().lower().replace(\" \", \"_\").replace(\"[\", \"\").replace(\"]\", \"\") for col in df.columns]\n",
    "\n",
    "# Build CREATE TABLE statement based on DataFrame structure\n",
    "def generate_create_table(df, full_table_name):\n",
    "    sql_fields = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"int64\":\n",
    "            col_type = \"BIGINT\"\n",
    "        elif df[col].dtype == \"float64\":\n",
    "            col_type = \"FLOAT\"\n",
    "        else:\n",
    "            col_type = \"TEXT\"\n",
    "        sql_fields.append(f\"{col} {col_type}\")\n",
    "    return f\"CREATE TABLE {full_table_name} ({', '.join(sql_fields)});\"\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    connection = psycopg2.connect(\n",
    "        host=hostname,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password,\n",
    "        port=port\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    print(\"✅ Connected to PostgreSQL!\")\n",
    "\n",
    "    # Step 1: Create your schema if it doesn't exist\n",
    "    cursor.execute(sql.SQL(\"CREATE SCHEMA IF NOT EXISTS {} AUTHORIZATION {}\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(username)\n",
    "    ))\n",
    "    print(f\"🏗️ Created/confirmed schema `{schema_name}`.\")\n",
    "\n",
    "    # Step 2: Drop table if exists\n",
    "    cursor.execute(sql.SQL(\"DROP TABLE IF EXISTS {}.{}\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(table_name)\n",
    "    ))\n",
    "    print(f\"🧹 Dropped table `{schema_name}.{table_name}` if it existed.\")\n",
    "\n",
    "    # Step 3: Create table\n",
    "    full_table_name = f\"{schema_name}.{table_name}\"\n",
    "    create_sql = generate_create_table(df, full_table_name)\n",
    "    cursor.execute(create_sql)\n",
    "    print(f\"📦 Created table `{full_table_name}`.\")\n",
    "\n",
    "    # Step 4: Insert data in batches\n",
    "    batch_size = 500\n",
    "    total_records = len(df)\n",
    "    print(f\"⬆️ Inserting {total_records} records...\")\n",
    "\n",
    "    for start in range(0, total_records, batch_size):\n",
    "        end = min(start + batch_size, total_records)\n",
    "        batch = df.iloc[start:end]\n",
    "\n",
    "        columns = ', '.join(batch.columns)\n",
    "        values = ', '.join(['%s'] * len(batch.columns))\n",
    "        insert_sql = f\"INSERT INTO {full_table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "        records = [tuple(x) for x in batch.to_numpy()]\n",
    "        cursor.executemany(insert_sql, records)\n",
    "        connection.commit()\n",
    "        print(f\"✅ Inserted rows {start + 1} to {end}\")\n",
    "\n",
    "    print(\"🎉 All data inserted successfully into `{full_table_name}`!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error:\", e)\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"🔒 PostgreSQL connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
