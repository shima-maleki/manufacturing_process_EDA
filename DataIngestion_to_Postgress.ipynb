{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting data into Filess Cloud based Postgres Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  ('PostgreSQL 14.4 on aarch64-unknown-linux-musl, compiled by gcc (Alpine 11.2.1_git20220219) 11.2.1 20220219, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd \n",
    "\n",
    "hostname = \"bpd9p.h.filess.io\"\n",
    "database = \"database_wheneverof\"\n",
    "port = \"5432\"\n",
    "username = \"database_wheneverof\"\n",
    "password = \"b2bf3de4d74d8d014fc7370f7b911feeba371894\"\n",
    "\n",
    "# Establishing the connection\n",
    "conn = psycopg2.connect(\n",
    "   database=database, user=username, password=password, host=hostname, port=port\n",
    ")\n",
    "# Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Executing an MYSQL function using the execute() method\n",
    "cursor.execute(\"select version()\")\n",
    "\n",
    "# Fetch a single row using fetchone() method.\n",
    "data = cursor.fetchone()\n",
    "print(\"Connection established to: \", data)\n",
    "\n",
    "# Closing the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data into postgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to PostgreSQL!\n",
      "ğŸ—ï¸ Created/confirmed schema `myschema`.\n",
      "ğŸ§¹ Dropped table `myschema.machine_data` if it existed.\n",
      "ğŸ“¦ Created table `myschema.machine_data`.\n",
      "â¬†ï¸ Inserting 10000 records...\n",
      "âœ… Inserted rows 1 to 500\n",
      "âœ… Inserted rows 501 to 1000\n",
      "âœ… Inserted rows 1001 to 1500\n",
      "âœ… Inserted rows 1501 to 2000\n",
      "âœ… Inserted rows 2001 to 2500\n",
      "âœ… Inserted rows 2501 to 3000\n",
      "âœ… Inserted rows 3001 to 3500\n",
      "âœ… Inserted rows 3501 to 4000\n",
      "âœ… Inserted rows 4001 to 4500\n",
      "âœ… Inserted rows 4501 to 5000\n",
      "âœ… Inserted rows 5001 to 5500\n",
      "âœ… Inserted rows 5501 to 6000\n",
      "âœ… Inserted rows 6001 to 6500\n",
      "âœ… Inserted rows 6501 to 7000\n",
      "âœ… Inserted rows 7001 to 7500\n",
      "âœ… Inserted rows 7501 to 8000\n",
      "âœ… Inserted rows 8001 to 8500\n",
      "âœ… Inserted rows 8501 to 9000\n",
      "âœ… Inserted rows 9001 to 9500\n",
      "âœ… Inserted rows 9501 to 10000\n",
      "ğŸ‰ All data inserted successfully into `{full_table_name}`!\n",
      "ğŸ”’ PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# PostgreSQL connection details\n",
    "hostname = \"bpd9p.h.filess.io\"\n",
    "database = \"database_wheneverof\"\n",
    "port = 5432\n",
    "username = \"database_wheneverof\"\n",
    "password = \"b2bf3de4d74d8d014fc7370f7b911feeba371894\"\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = \"data/data.csv\"  # <- Replace with your actual file path\n",
    "table_name = \"machine_data\"\n",
    "schema_name = \"myschema\"  # <- You can rename this schema if you want\n",
    "\n",
    "# Load the CSV into pandas\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Clean column names to be SQL-safe\n",
    "df.columns = [col.strip().lower().replace(\" \", \"_\").replace(\"[\", \"\").replace(\"]\", \"\") for col in df.columns]\n",
    "\n",
    "# Build CREATE TABLE statement based on DataFrame structure\n",
    "def generate_create_table(df, full_table_name):\n",
    "    sql_fields = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"int64\":\n",
    "            col_type = \"BIGINT\"\n",
    "        elif df[col].dtype == \"float64\":\n",
    "            col_type = \"FLOAT\"\n",
    "        else:\n",
    "            col_type = \"TEXT\"\n",
    "        sql_fields.append(f\"{col} {col_type}\")\n",
    "    return f\"CREATE TABLE {full_table_name} ({', '.join(sql_fields)});\"\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    connection = psycopg2.connect(\n",
    "        host=hostname,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password,\n",
    "        port=port\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    print(\"âœ… Connected to PostgreSQL!\")\n",
    "\n",
    "    # Step 1: Create your schema if it doesn't exist\n",
    "    cursor.execute(sql.SQL(\"CREATE SCHEMA IF NOT EXISTS {} AUTHORIZATION {}\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(username)\n",
    "    ))\n",
    "    print(f\"ğŸ—ï¸ Created/confirmed schema `{schema_name}`.\")\n",
    "\n",
    "    # Step 2: Drop table if exists\n",
    "    cursor.execute(sql.SQL(\"DROP TABLE IF EXISTS {}.{}\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(table_name)\n",
    "    ))\n",
    "    print(f\"ğŸ§¹ Dropped table `{schema_name}.{table_name}` if it existed.\")\n",
    "\n",
    "    # Step 3: Create table\n",
    "    full_table_name = f\"{schema_name}.{table_name}\"\n",
    "    create_sql = generate_create_table(df, full_table_name)\n",
    "    cursor.execute(create_sql)\n",
    "    print(f\"ğŸ“¦ Created table `{full_table_name}`.\")\n",
    "\n",
    "    # Step 4: Insert data in batches\n",
    "    batch_size = 500\n",
    "    total_records = len(df)\n",
    "    print(f\"â¬†ï¸ Inserting {total_records} records...\")\n",
    "\n",
    "    for start in range(0, total_records, batch_size):\n",
    "        end = min(start + batch_size, total_records)\n",
    "        batch = df.iloc[start:end]\n",
    "\n",
    "        columns = ', '.join(batch.columns)\n",
    "        values = ', '.join(['%s'] * len(batch.columns))\n",
    "        insert_sql = f\"INSERT INTO {full_table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "        records = [tuple(x) for x in batch.to_numpy()]\n",
    "        cursor.executemany(insert_sql, records)\n",
    "        connection.commit()\n",
    "        print(f\"âœ… Inserted rows {start + 1} to {end}\")\n",
    "\n",
    "    print(\"ğŸ‰ All data inserted successfully into `{full_table_name}`!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âŒ Error:\", e)\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"ğŸ”’ PostgreSQL connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
